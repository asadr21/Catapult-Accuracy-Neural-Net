{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1YXb0cilediL",
        "outputId": "179f899b-678d-4d64-91f1-aa62d2a6e6bc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import model_selection\n",
        "from google.colab import files\n",
        "\n",
        "df = pandas.read_csv('http://pogo.software/me4ml/dataset1.csv')\n",
        "\n",
        "X = np.zeros([2, 2000]).T\n",
        "X_scaled = X\n",
        "Y = np.zeros([2000]).T\n",
        "X[:, 0] = np.array(df['Arm length (m)'][:])\n",
        "X[:, 1] = np.array(df['Ball weight (kg)'][:])\n",
        "X[:, 2] = np.array(df['Ball radius (mm)'][:])\n",
        "X[:, 3] = np.array(df['Air temperature (deg C)'][:])\n",
        "X[:, 4] = np.array(df['Spring constant (N per m)'][:])\n",
        "X[:, 5] = np.array(df['Device weight (kg)'][:])\n",
        "Y = np.array(df['Target hit'][:]).T\n",
        "\n",
        "def scaling(x, mean, std):\n",
        "    scaled = (x - mean)/std\n",
        "    return scaled\n",
        "\n",
        "scaling_param = np.zeros([2, 6])\n",
        "for i in range (6):\n",
        "  scaling_param[0, i] = np.mean(X[:, i])\n",
        "  scaling_param[1, i] = np.std(X[:, i])\n",
        "  X_scaled[:, i] = scaling(X[:, i], scaling_param[0, i], scaling_param[1, i])\n",
        "\n",
        "np.savetxt('Raja-Asad-dataset1.txt', scaling_param)\n",
        "\n",
        "\n",
        "from keras.utils import *\n",
        "y_binary = to_categorical(Y)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=3, activation='relu', input_dim=6))\n",
        "model.add(Dense(units=2, activation='relu'))\n",
        "#model.add(Dense(units=7, activation='relu'))\n",
        "#model.add(Dense(units=6, activation='relu'))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_scaled, y_binary, epochs=100, batch_size=20)\n",
        "model.save('Raja-Asad-dataset1.h5')\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fraction_correct = np.zeros(5)\n",
        "z = -1\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "  z = z + 1\n",
        "  X_train = X_scaled[train_index]\n",
        "  y_train = y_binary[train_index]\n",
        "  X_test = X_scaled[test_index]\n",
        "  y_test = y_binary[test_index]\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  y_test_model = model.predict(X_test)\n",
        "  #loop through to compare the test data output to what it should be\n",
        "  #\tand obtain the error)\n",
        "  number_correct = 0\n",
        "  for i in range(len(y_test)):\n",
        "    if np.round(y_test[i, 1]) == np.round(y_test_model[i, 1]):\n",
        "      number_correct += 1\n",
        "\n",
        "  fraction_correct[z] = 1.0 * number_correct / len(y_test)\n",
        "\n",
        "\n",
        "\n",
        "files.download('Raja-Asad-dataset1.h5')\n",
        "files.download('Raja-Asad-dataset1.txt')\n",
        "\n",
        "fraction_correct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.7679 - accuracy: 0.5565\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.5750\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6050\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6415\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6780\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7075\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7405\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7730\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8055\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8360\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8625\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8810\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8940\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8970\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9015\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9020\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.9040\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9025\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.9045\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9035\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9055\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9050\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9045\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9070\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9075\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9065\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9095\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9070\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9110\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9110\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9095\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9105\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9120\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9130\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9130\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9145\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9125\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9135\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9110\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9130\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9145\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9110\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9130\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9170\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9135\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9110\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9100\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9115\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9120\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9130\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9135\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9095\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9120\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9130\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9125\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9125\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9110\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9140\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9115\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9135\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9110\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9145\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9135\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9125\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9135\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9140\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9145\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9155\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9135\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9135\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9130\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9140\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9120\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9120\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9150\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9160\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9140\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9145\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9120\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9140\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9140\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9160\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9145\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9180\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9150\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9160\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9165\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9175\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9190\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9170\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9180\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9160\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9170\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9185\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9190\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9200\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9210\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9170\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9210\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9195\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9187\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9187\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9181\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9181\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_66e5b243-31f5-4a78-a43f-f8ef9989e566\", \"Raja-Asad-dataset1.h5\", 19728)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_25d8922f-b5f9-437f-a249-cda2e016a053\", \"Raja-Asad-dataset1.txt\", 300)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.925 , 0.9275, 0.92  , 0.9225, 0.9125])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l22gpF2QCH_J",
        "outputId": "da683db2-d971-4791-cd5f-f01832adbff2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import model_selection\n",
        "from google.colab import files\n",
        "\n",
        "df = pandas.read_csv('http://pogo.software/me4ml/dataset2.csv')\n",
        "\n",
        "X = np.zeros([6, 4000]).T\n",
        "X_scaled = X\n",
        "Y = np.zeros([4000]).T\n",
        "X[:, 0] = np.array(df['Arm length (m)'][:])\n",
        "X[:, 1] = np.array(df['Ball weight (kg)'][:])\n",
        "X[:, 2] = np.array(df['Ball radius (mm)'][:])\n",
        "X[:, 3] = np.array(df['Air temperature (deg C)'][:])\n",
        "X[:, 4] = np.array(df['Spring constant (N per m)'][:])\n",
        "X[:, 5] = np.array(df['Device weight (kg)'][:])\n",
        "Y = np.array(df['Target hit'][:]).T\n",
        "\n",
        "def scaling(x, mean, std):\n",
        "    scaled = (x - mean)/std\n",
        "    return scaled\n",
        "\n",
        "scaling_param = np.zeros([2, 6])\n",
        "for i in range (6):\n",
        "  scaling_param[0, i] = np.mean(X[:, i])\n",
        "  scaling_param[1, i] = np.std(X[:, i])\n",
        "  X_scaled[:, i] = scaling(X[:, i], scaling_param[0, i], scaling_param[1, i])\n",
        "\n",
        "np.savetxt('Raja-Asad-dataset2.txt', scaling_param)\n",
        "\n",
        "\n",
        "from keras.utils import *\n",
        "y_binary = to_categorical(Y)\n",
        "\n",
        "activation = ['tanh', 'relu', 'elu', 'exponential', 'selu', 'softmax', 'softplus']\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=6, activation='tanh', input_dim=6))\n",
        "model.add(Dense(units=8, activation='tanh'))\n",
        "model.add(Dense(units=8, activation='exponential'))\n",
        "model.add(Dense(units=6, activation='elu'))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_scaled, y_binary, epochs=400, batch_size=20)\n",
        "model.save('Raja-Asad-dataset2.h5')\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fraction_correct = np.zeros(5)\n",
        "z = -1\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "  z = z + 1\n",
        "  X_train = X_scaled[train_index]\n",
        "  y_train = y_binary[train_index]\n",
        "  X_test = X_scaled[test_index]\n",
        "  y_test = y_binary[test_index]\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  y_test_model = model.predict(X_test)\n",
        "  #loop through to compare the test data output to what it should be\n",
        "  #\tand obtain the error)\n",
        "  number_correct = 0\n",
        "  for i in range(len(y_test)):\n",
        "    if np.round(y_test[i, 1]) == np.round(y_test_model[i, 1]):\n",
        "      number_correct += 1\n",
        "\n",
        "  fraction_correct[z] = 1.0 * number_correct / len(y_test)\n",
        "\n",
        "\n",
        "files.download('Raja-Asad-dataset2.h5')\n",
        "files.download('Raja-Asad-dataset2.txt')\n",
        "#training_predict = model.predict(X_scaled)\n",
        "\n",
        "print(fraction_correct)\n",
        "print(np.mean(fraction_correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.5182\n",
            "Epoch 2/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5567\n",
            "Epoch 3/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5753\n",
            "Epoch 4/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5788\n",
            "Epoch 5/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5828\n",
            "Epoch 6/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.5920\n",
            "Epoch 7/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5943\n",
            "Epoch 8/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6003\n",
            "Epoch 9/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6090\n",
            "Epoch 10/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6085\n",
            "Epoch 11/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6183\n",
            "Epoch 12/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6145\n",
            "Epoch 13/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6185\n",
            "Epoch 14/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6148\n",
            "Epoch 15/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6102\n",
            "Epoch 16/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6152\n",
            "Epoch 17/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6105\n",
            "Epoch 18/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6202\n",
            "Epoch 19/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6168\n",
            "Epoch 20/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6165\n",
            "Epoch 21/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6200\n",
            "Epoch 22/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6150\n",
            "Epoch 23/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6177\n",
            "Epoch 24/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6187\n",
            "Epoch 25/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6235\n",
            "Epoch 26/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6208\n",
            "Epoch 27/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6205\n",
            "Epoch 28/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6235\n",
            "Epoch 29/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6245\n",
            "Epoch 30/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6277\n",
            "Epoch 31/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6217\n",
            "Epoch 32/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6240\n",
            "Epoch 33/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6300\n",
            "Epoch 34/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6373\n",
            "Epoch 35/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6395\n",
            "Epoch 36/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6367\n",
            "Epoch 37/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6470\n",
            "Epoch 38/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6457\n",
            "Epoch 39/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6540\n",
            "Epoch 40/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6515\n",
            "Epoch 41/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6582\n",
            "Epoch 42/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6645\n",
            "Epoch 43/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6680\n",
            "Epoch 44/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6775\n",
            "Epoch 45/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6770\n",
            "Epoch 46/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6740\n",
            "Epoch 47/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6817\n",
            "Epoch 48/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6830\n",
            "Epoch 49/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6935\n",
            "Epoch 50/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6858\n",
            "Epoch 51/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6938\n",
            "Epoch 52/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6892\n",
            "Epoch 53/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6973\n",
            "Epoch 54/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6960\n",
            "Epoch 55/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7050\n",
            "Epoch 56/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7003\n",
            "Epoch 57/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7020\n",
            "Epoch 58/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7045\n",
            "Epoch 59/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6960\n",
            "Epoch 60/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7028\n",
            "Epoch 61/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7063\n",
            "Epoch 62/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7130\n",
            "Epoch 63/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7042\n",
            "Epoch 64/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7088\n",
            "Epoch 65/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7080\n",
            "Epoch 66/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7067\n",
            "Epoch 67/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7110\n",
            "Epoch 68/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7122\n",
            "Epoch 69/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7117\n",
            "Epoch 70/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7095\n",
            "Epoch 71/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7105\n",
            "Epoch 72/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7157\n",
            "Epoch 73/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7025\n",
            "Epoch 74/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7125\n",
            "Epoch 75/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7143\n",
            "Epoch 76/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7085\n",
            "Epoch 77/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7155\n",
            "Epoch 78/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7080\n",
            "Epoch 79/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7105\n",
            "Epoch 80/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7200\n",
            "Epoch 81/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7168\n",
            "Epoch 82/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7113\n",
            "Epoch 83/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7163\n",
            "Epoch 84/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7092\n",
            "Epoch 85/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7113\n",
            "Epoch 86/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7207\n",
            "Epoch 87/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7165\n",
            "Epoch 88/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7135\n",
            "Epoch 89/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7175\n",
            "Epoch 90/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7205\n",
            "Epoch 91/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7190\n",
            "Epoch 92/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7200\n",
            "Epoch 93/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7247\n",
            "Epoch 94/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7230\n",
            "Epoch 95/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7205\n",
            "Epoch 96/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7212\n",
            "Epoch 97/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7253\n",
            "Epoch 98/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7255\n",
            "Epoch 99/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7240\n",
            "Epoch 100/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7243\n",
            "Epoch 101/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7195\n",
            "Epoch 102/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7195\n",
            "Epoch 103/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7265\n",
            "Epoch 104/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7278\n",
            "Epoch 105/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7335\n",
            "Epoch 106/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7345\n",
            "Epoch 107/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7278\n",
            "Epoch 108/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7250\n",
            "Epoch 109/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7278\n",
            "Epoch 110/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7335\n",
            "Epoch 111/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7283\n",
            "Epoch 112/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7387\n",
            "Epoch 113/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7370\n",
            "Epoch 114/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7408\n",
            "Epoch 115/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7418\n",
            "Epoch 116/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7390\n",
            "Epoch 117/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7393\n",
            "Epoch 118/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7462\n",
            "Epoch 119/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7480\n",
            "Epoch 120/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7483\n",
            "Epoch 121/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7477\n",
            "Epoch 122/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7473\n",
            "Epoch 123/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7527\n",
            "Epoch 124/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7473\n",
            "Epoch 125/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7607\n",
            "Epoch 126/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7515\n",
            "Epoch 127/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7533\n",
            "Epoch 128/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7620\n",
            "Epoch 129/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7620\n",
            "Epoch 130/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7577\n",
            "Epoch 131/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7535\n",
            "Epoch 132/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7617\n",
            "Epoch 133/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7600\n",
            "Epoch 134/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7582\n",
            "Epoch 135/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7573\n",
            "Epoch 136/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7625\n",
            "Epoch 137/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7588\n",
            "Epoch 138/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7648\n",
            "Epoch 139/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7670\n",
            "Epoch 140/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7650\n",
            "Epoch 141/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7635\n",
            "Epoch 142/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7642\n",
            "Epoch 143/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7613\n",
            "Epoch 144/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7642\n",
            "Epoch 145/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7665\n",
            "Epoch 146/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7632\n",
            "Epoch 147/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7678\n",
            "Epoch 148/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7720\n",
            "Epoch 149/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7675\n",
            "Epoch 150/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7705\n",
            "Epoch 151/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7692\n",
            "Epoch 152/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7657\n",
            "Epoch 153/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7660\n",
            "Epoch 154/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7738\n",
            "Epoch 155/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7670\n",
            "Epoch 156/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7680\n",
            "Epoch 157/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7690\n",
            "Epoch 158/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7700\n",
            "Epoch 159/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7703\n",
            "Epoch 160/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7703\n",
            "Epoch 161/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7710\n",
            "Epoch 162/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7692\n",
            "Epoch 163/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7703\n",
            "Epoch 164/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7703\n",
            "Epoch 165/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7795\n",
            "Epoch 166/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7735\n",
            "Epoch 167/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7730\n",
            "Epoch 168/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7670\n",
            "Epoch 169/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7678\n",
            "Epoch 170/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7747\n",
            "Epoch 171/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7695\n",
            "Epoch 172/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7690\n",
            "Epoch 173/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7735\n",
            "Epoch 174/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7713\n",
            "Epoch 175/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7750\n",
            "Epoch 176/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7725\n",
            "Epoch 177/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7730\n",
            "Epoch 178/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7713\n",
            "Epoch 179/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7703\n",
            "Epoch 180/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7740\n",
            "Epoch 181/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7707\n",
            "Epoch 182/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7735\n",
            "Epoch 183/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7720\n",
            "Epoch 184/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7728\n",
            "Epoch 185/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7768\n",
            "Epoch 186/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7703\n",
            "Epoch 187/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7673\n",
            "Epoch 188/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7720\n",
            "Epoch 189/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7755\n",
            "Epoch 190/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7760\n",
            "Epoch 191/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7772\n",
            "Epoch 192/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7747\n",
            "Epoch 193/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7745\n",
            "Epoch 194/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7797\n",
            "Epoch 195/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7735\n",
            "Epoch 196/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7725\n",
            "Epoch 197/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7800\n",
            "Epoch 198/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7753\n",
            "Epoch 199/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7775\n",
            "Epoch 200/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7778\n",
            "Epoch 201/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7747\n",
            "Epoch 202/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778\n",
            "Epoch 203/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7770\n",
            "Epoch 204/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7790\n",
            "Epoch 205/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7797\n",
            "Epoch 206/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7835\n",
            "Epoch 207/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7755\n",
            "Epoch 208/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7763\n",
            "Epoch 209/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7750\n",
            "Epoch 210/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7692\n",
            "Epoch 211/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7747\n",
            "Epoch 212/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7840\n",
            "Epoch 213/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7847\n",
            "Epoch 214/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7790\n",
            "Epoch 215/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7793\n",
            "Epoch 216/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7790\n",
            "Epoch 217/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7785\n",
            "Epoch 218/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7795\n",
            "Epoch 219/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7788\n",
            "Epoch 220/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7755\n",
            "Epoch 221/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7797\n",
            "Epoch 222/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7797\n",
            "Epoch 223/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7770\n",
            "Epoch 224/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7820\n",
            "Epoch 225/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7797\n",
            "Epoch 226/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7832\n",
            "Epoch 227/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7835\n",
            "Epoch 228/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7775\n",
            "Epoch 229/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7840\n",
            "Epoch 230/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7812\n",
            "Epoch 231/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7828\n",
            "Epoch 232/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7850\n",
            "Epoch 233/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7832\n",
            "Epoch 234/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7847\n",
            "Epoch 235/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7883\n",
            "Epoch 236/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7828\n",
            "Epoch 237/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7890\n",
            "Epoch 238/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7868\n",
            "Epoch 239/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865\n",
            "Epoch 240/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7872\n",
            "Epoch 241/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7883\n",
            "Epoch 242/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7845\n",
            "Epoch 243/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7872\n",
            "Epoch 244/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7870\n",
            "Epoch 245/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7915\n",
            "Epoch 246/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7893\n",
            "Epoch 247/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7870\n",
            "Epoch 248/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7845\n",
            "Epoch 249/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7885\n",
            "Epoch 250/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7895\n",
            "Epoch 251/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847\n",
            "Epoch 252/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7977\n",
            "Epoch 253/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7950\n",
            "Epoch 254/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7897\n",
            "Epoch 255/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7945\n",
            "Epoch 256/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7930\n",
            "Epoch 257/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7947\n",
            "Epoch 258/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7987\n",
            "Epoch 259/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7947\n",
            "Epoch 260/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7983\n",
            "Epoch 261/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7975\n",
            "Epoch 262/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7968\n",
            "Epoch 263/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8008\n",
            "Epoch 264/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8015\n",
            "Epoch 265/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7958\n",
            "Epoch 266/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7952\n",
            "Epoch 267/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7952\n",
            "Epoch 268/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7968\n",
            "Epoch 269/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8010\n",
            "Epoch 270/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7993\n",
            "Epoch 271/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8080\n",
            "Epoch 272/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7997\n",
            "Epoch 273/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8043\n",
            "Epoch 274/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8035\n",
            "Epoch 275/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8043\n",
            "Epoch 276/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8052\n",
            "Epoch 277/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8083\n",
            "Epoch 278/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8012\n",
            "Epoch 279/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8050\n",
            "Epoch 280/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8075\n",
            "Epoch 281/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8050\n",
            "Epoch 282/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8058\n",
            "Epoch 283/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8092\n",
            "Epoch 284/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8067\n",
            "Epoch 285/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8075\n",
            "Epoch 286/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8095\n",
            "Epoch 287/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8080\n",
            "Epoch 288/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8062\n",
            "Epoch 289/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8115\n",
            "Epoch 290/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8045\n",
            "Epoch 291/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8138\n",
            "Epoch 292/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8127\n",
            "Epoch 293/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8112\n",
            "Epoch 294/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8102\n",
            "Epoch 295/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8142\n",
            "Epoch 296/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8138\n",
            "Epoch 297/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8150\n",
            "Epoch 298/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8098\n",
            "Epoch 299/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8148\n",
            "Epoch 300/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8152\n",
            "Epoch 301/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8163\n",
            "Epoch 302/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8142\n",
            "Epoch 303/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8145\n",
            "Epoch 304/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8148\n",
            "Epoch 305/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8223\n",
            "Epoch 306/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8183\n",
            "Epoch 307/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8145\n",
            "Epoch 308/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8145\n",
            "Epoch 309/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8217\n",
            "Epoch 310/400\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8160\n",
            "Epoch 311/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8210\n",
            "Epoch 312/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8198\n",
            "Epoch 313/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8142\n",
            "Epoch 314/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8223\n",
            "Epoch 315/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8195\n",
            "Epoch 316/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8177\n",
            "Epoch 317/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8225\n",
            "Epoch 318/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8205\n",
            "Epoch 319/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8215\n",
            "Epoch 320/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8235\n",
            "Epoch 321/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8230\n",
            "Epoch 322/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8207\n",
            "Epoch 323/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8183\n",
            "Epoch 324/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8230\n",
            "Epoch 325/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8202\n",
            "Epoch 326/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8248\n",
            "Epoch 327/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8260\n",
            "Epoch 328/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8242\n",
            "Epoch 329/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8225\n",
            "Epoch 330/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8280\n",
            "Epoch 331/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8240\n",
            "Epoch 332/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8235\n",
            "Epoch 333/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8192\n",
            "Epoch 334/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8265\n",
            "Epoch 335/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8267\n",
            "Epoch 336/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8263\n",
            "Epoch 337/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8260\n",
            "Epoch 338/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8217\n",
            "Epoch 339/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8255\n",
            "Epoch 340/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8298\n",
            "Epoch 341/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8265\n",
            "Epoch 342/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8267\n",
            "Epoch 343/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8255\n",
            "Epoch 344/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8270\n",
            "Epoch 345/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8300\n",
            "Epoch 346/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8270\n",
            "Epoch 347/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8288\n",
            "Epoch 348/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8280\n",
            "Epoch 349/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8253\n",
            "Epoch 350/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8313\n",
            "Epoch 351/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8257\n",
            "Epoch 352/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8253\n",
            "Epoch 353/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8298\n",
            "Epoch 354/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8320\n",
            "Epoch 355/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8255\n",
            "Epoch 356/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8328\n",
            "Epoch 357/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8298\n",
            "Epoch 358/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8282\n",
            "Epoch 359/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8340\n",
            "Epoch 360/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8345\n",
            "Epoch 361/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8317\n",
            "Epoch 362/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8282\n",
            "Epoch 363/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8298\n",
            "Epoch 364/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8332\n",
            "Epoch 365/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8300\n",
            "Epoch 366/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8320\n",
            "Epoch 367/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8328\n",
            "Epoch 368/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8322\n",
            "Epoch 369/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8380\n",
            "Epoch 370/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8320\n",
            "Epoch 371/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8335\n",
            "Epoch 372/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8345\n",
            "Epoch 373/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8342\n",
            "Epoch 374/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8330\n",
            "Epoch 375/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8338\n",
            "Epoch 376/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8338\n",
            "Epoch 377/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8375\n",
            "Epoch 378/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8395\n",
            "Epoch 379/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8357\n",
            "Epoch 380/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8342\n",
            "Epoch 381/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8355\n",
            "Epoch 382/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8385\n",
            "Epoch 383/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8388\n",
            "Epoch 384/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8393\n",
            "Epoch 385/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8393\n",
            "Epoch 386/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8395\n",
            "Epoch 387/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8335\n",
            "Epoch 388/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8390\n",
            "Epoch 389/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8395\n",
            "Epoch 390/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8403\n",
            "Epoch 391/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8378\n",
            "Epoch 392/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8393\n",
            "Epoch 393/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8372\n",
            "Epoch 394/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8395\n",
            "Epoch 395/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8415\n",
            "Epoch 396/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8370\n",
            "Epoch 397/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8400\n",
            "Epoch 398/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8447\n",
            "Epoch 399/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8435\n",
            "Epoch 400/400\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8443\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8512\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8400\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8478\n",
            "  1/100 [..............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0050s). Check your callbacks.\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8409\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_627d9716-87b3-4a1b-aadd-4ea981eeb514\", \"Raja-Asad-dataset2.h5\", 48840)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1fabd7b8-ffcc-472e-a0d9-589c157140d6\", \"Raja-Asad-dataset2.txt\", 300)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.8175  0.86125 0.82875 0.845   0.86625]\n",
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}